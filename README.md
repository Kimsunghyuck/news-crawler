# Anthropic 뉴스 크롤러

Anthropic 웹사이트(https://www.anthropic.com/news)에서 최신 뉴스를 자동으로 크롤링하고 한국어 보고서로 변환하는 완전 자동화 시스템입니다.

## 🌟 주요 기능

- ✅ Anthropic 뉴스 페이지에서 최신 뉴스 자동 크롤링
- ✅ 뉴스 제목, URL, 날짜, 카테고리 추출
- ✅ JSON 형식으로 데이터 저장
- ✅ **한국어 보고서 자동 생성** - 크롤링 후 즉시 보고서 생성
- ✅ **매일 아침 9시 자동 실행** - 정해진 시간에 자동 크롤링
- ✅ **날짜별 보고서 관리** - 크롤링 날짜가 파일명에 포함
- ✅ 중복 제거 및 증분 업데이트
- ✅ 에러 처리 및 재시도 로직
- ✅ 상세한 로깅

## 📁 프로젝트 구조

```
document-test/
├── config.py           # 설정 파일 (URL, 스케줄링 시간 등)
├── crawler.py          # 크롤링 메인 로직 + 자동 보고서 생성
├── parser.py           # HTML 파싱 함수
├── report_generator.py # 한국어 보고서 생성 모듈
├── scheduler.py        # 자동 스케줄링 모듈
├── requirements.txt    # 필요한 라이브러리
├── data/              # 크롤링 데이터 저장 폴더
│   └── news.json      # 뉴스 데이터 (JSON)
├── reports/           # 보고서 저장 폴더
│   └── anthropic_news_report_2025-12-01.md
└── logs/              # 로그 파일 폴더
    └── crawler.log    # 크롤링 로그
```

## 🚀 설치 및 실행

### 1. 필요한 라이브러리 설치

```powershell
pip install -r requirements.txt
```

### 2-A. 단일 실행 (한 번만 크롤링)

```powershell
python crawler.py
```

### 2-B. 자동 스케줄링 실행 (추천)

```powershell
python scheduler.py
```

**자동 스케줄링 모드**에서는:
- 프로그램 시작 시 즉시 한 번 크롤링 실행
- 이후 설정된 주기(기본 6시간)마다 자동 실행
- 백그라운드에서 계속 실행되며 새 뉴스 자동 수집
- `Ctrl+C`로 종료 가능

## ⚙️ 설정 변경

`config.py` 파일에서 다양한 설정을 변경할 수 있습니다:

### 크롤링 주기 변경

```python
# 6시간마다 실행 (기본값)
CRAWL_INTERVAL_HOURS = 6

# 예: 3시간마다 실행
CRAWL_INTERVAL_HOURS = 3

# 예: 매일 1번 실행
CRAWL_INTERVAL_HOURS = 24
```

### 특정 시간에 실행 (선택사항)

`scheduler.py`에서 아래 주석을 해제하고 사용:

```python
# config.py에 추가
CRAWL_TIME = "09:00"  # 매일 오전 9시

# scheduler.py에서 해당 부분 주석 해제
schedule.every().day.at(CRAWL_TIME).do(scheduled_crawl)
```

## 📊 출력 데이터 형식

`data/news.json` 파일에 다음 형식으로 저장됩니다:

```json
[
  {
    "title": "Introducing Claude Opus 4.5",
    "url": "https://www.anthropic.com/news/claude-opus-4-5",
    "date": "Nov 25, 2025",
    "category": "Announcements",
    "scraped_at": "2025-12-01T10:30:00.123456"
  },
  {
    "title": "Claude now available in Microsoft Foundry",
    "url": "https://www.anthropic.com/news/microsoft-partnership",
    "date": "Nov 19, 2025",
    "category": "Product",
    "scraped_at": "2025-12-01T10:30:00.123456"
  }
]
```

## 🤖 자동 스케줄링이란?

자동 스케줄링은 프로그램이 **정해진 시간이나 주기마다 자동으로 실행**되는 기능입니다.

### 동작 방식

1. **프로그램 실행**: `python scheduler.py` 실행
2. **초기 크롤링**: 즉시 한 번 뉴스 크롤링
3. **대기**: 설정된 시간(예: 6시간) 동안 대기
4. **자동 실행**: 6시간 후 자동으로 다시 크롤링
5. **반복**: 3-4 단계를 계속 반복

### 장점

- ✅ 수동으로 실행할 필요 없음
- ✅ 최신 뉴스를 놓치지 않고 자동 수집
- ✅ 백그라운드에서 계속 실행
- ✅ 일정 간격으로 데이터 업데이트

### 실행 예시

```
============================================================
🤖 Anthropic 뉴스 크롤러 자동 스케줄러 시작
============================================================
✓ 스케줄 등록: 6시간마다 실행

🚀 초기 크롤링 시작 (프로그램 시작 시)
============================================================
뉴스 크롤링 시작
현재 시간: 2025-12-01 10:00:00
============================================================
페이지 가져오기 성공: https://www.anthropic.com/news
파싱 완료: 15개 뉴스 항목 발견
새로운 뉴스 5개 발견
뉴스 20개를 data/news.json에 저장 완료
============================================================

⏰ 다음 크롤링 예정 시간: 2025-12-01 16:00:00

============================================================
스케줄러 실행 중... (Ctrl+C로 종료)
============================================================
```

## 📝 로그 확인

크롤링 진행 상황과 오류는 다음 위치에 기록됩니다:

- **파일**: `logs/crawler.log`
- **콘솔**: 실시간 출력

## 🛠️ 문제 해결

### 크롤링 실패 시

1. 인터넷 연결 확인
2. `logs/crawler.log` 파일에서 오류 메시지 확인
3. Anthropic 웹사이트가 정상인지 확인

### 데이터가 저장되지 않을 때

1. `data/` 폴더가 자동 생성되었는지 확인
2. 파일 쓰기 권한 확인
3. 로그에서 저장 관련 오류 확인

## 📦 필요한 라이브러리

- `requests`: HTTP 요청
- `beautifulsoup4`: HTML 파싱
- `lxml`: 파싱 엔진
- `schedule`: 자동 스케줄링
- `python-dateutil`: 날짜 처리

## 🔄 업데이트 전략

- 기존 뉴스와 새 뉴스를 **자동으로 병합**
- URL 기준 **중복 제거**
- 날짜 기준 **최신순 정렬**
- 이미 수집한 뉴스는 건너뛰고 새 뉴스만 추가

## 💡 활용 방법

1. **정기 모니터링**: 자동 스케줄러로 최신 뉴스 지속 수집
2. **데이터 분석**: JSON 데이터를 활용해 뉴스 트렌드 분석
3. **알림 시스템**: 새 뉴스 발견 시 이메일/Slack 알림 추가 가능
4. **데이터베이스 연동**: JSON 대신 DB에 저장하도록 확장 가능

## 📄 라이선스

개인 및 교육 목적으로 자유롭게 사용 가능합니다.

---

**만든 날짜**: 2025년 12월 1일
