"""
ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í•œêµ­ì–´ ë³´ê³ ì„œë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ
ì¹´í…Œê³ ë¦¬/ì†ŒìŠ¤ë³„ ê°œë³„ ë³´ê³ ì„œ ë° í†µí•© ë³´ê³ ì„œ ìƒì„±
"""

import json
import os
from datetime import datetime, timezone, timedelta
from collections import defaultdict
import re
from config import (
    NEWS_SOURCES, CATEGORY_EN_MAP, SOURCE_EN_MAP,
    REPORT_TEMPLATE, COMBINED_REPORT_TEMPLATE, NEWS_JSON_TEMPLATE
)

# í•œêµ­ ì‹œê°„ëŒ€ (KST = UTC+9)
KST = timezone(timedelta(hours=9))

def get_kst_now():
    """í•œêµ­ ì‹œê°„(KST)ìœ¼ë¡œ í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(KST)


def get_category_source_json_path(category: str, source: str, date: str) -> str:
    """ì¹´í…Œê³ ë¦¬/ì†ŒìŠ¤ë³„ JSON íŒŒì¼ ê²½ë¡œ ìƒì„±"""
    category_en = CATEGORY_EN_MAP.get(category, category.lower())
    source_en = SOURCE_EN_MAP.get(source, source.lower().replace(' ', '_'))
    return NEWS_JSON_TEMPLATE.format(category=category_en, source=source_en, date=date)


def load_all_news_by_date(date: str) -> dict:
    """
    íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ì¹´í…Œê³ ë¦¬/ì†ŒìŠ¤ ë‰´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        {category: {source: [news_items]}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    all_data = defaultdict(lambda: defaultdict(list))
    
    for category, sources in NEWS_SOURCES.items():
        for source_config in sources:
            source_name = source_config['name']
            json_path = get_category_source_json_path(category, source_name, date)
            
            if os.path.exists(json_path):
                try:
                    with open(json_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        all_data[category][source_name] = data
                except Exception as e:
                    print(f"âš ï¸ [{source_name}] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return all_data


def clean_title(title):
    """ì œëª©ì—ì„œ ë‚ ì§œì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ì œê±°í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤."""
    # ì›ë³¸ ì €ì¥
    original = title
    
    # ë‚ ì§œ íŒ¨í„´ ì œê±° (ì˜ˆ: "Nov 24, 2025", "Sep 29, 2025")
    title = re.sub(r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{1,2},\s+\d{4}', '', title)
    
    # ì¹´í…Œê³ ë¦¬ ì œê±°
    categories = ['Announcements', 'Product', 'Policy', 'Research', 'Economic Research', 'Company', 'Engineering']
    for cat in categories:
        title = title.replace(cat, '')
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    title = re.sub(r'\s+', ' ', title).strip()
    
    # ì œëª©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    if len(title) < 10:
        return original
    
    return title


def generate_source_report(category: str, source: str, news_list: list, date: str) -> str:
    """
    ê°œë³„ ì†ŒìŠ¤ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        category: ì¹´í…Œê³ ë¦¬
        source: ì†ŒìŠ¤ ì´ë¦„
        news_list: ë‰´ìŠ¤ í•­ëª© ë¦¬ìŠ¤íŠ¸
        date: ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
    """
    report = []
    report_date = datetime.strptime(date, '%Y-%m-%d').strftime('%Yë…„ %mì›” %dì¼')
    
    report.append(f"# ğŸ“° {category} - {source} ë‰´ìŠ¤ ë³´ê³ ì„œ\n\n")
    report.append(f"**ë³´ê³ ì„œ ë‚ ì§œ**: {report_date}\n")
    report.append(f"**ë³´ê³ ì„œ ìƒì„±ì¼**: {get_kst_now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')} (KST)\n")
    report.append(f"**ì´ ë‰´ìŠ¤ ê°œìˆ˜**: {len(news_list)}ê°œ\n")
    report.append("---\n\n")
    
    # ë‰´ìŠ¤ ëª©ë¡
    report.append("## ğŸ“‹ ë‰´ìŠ¤ ëª©ë¡\n\n")
    
    for idx, item in enumerate(news_list, 1):
        title = clean_title(item['title'])
        date_str = item.get('date', 'ë‚ ì§œ ë¯¸ìƒ')
        url = item['url']
        
        # scraped_atì„ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        scraped_at = item.get('scraped_at', '')
        if scraped_at:
            # ISO í˜•ì‹ì—ì„œ ë‚ ì§œì™€ ì‹œê°„ ì¶”ì¶œ (íƒ€ì„ì¡´ ì •ë³´ ì œê±°)
            # ì˜ˆ: 2025-12-02T09:08:57.123456+09:00 -> 2025-12-02 09:08:57
            scraped_time = scraped_at.split('.')[0].replace('T', ' ')
        else:
            scraped_time = 'ìˆ˜ì§‘ ì‹œê°„ ë¯¸ìƒ'
        
        report.append(f"### {idx}. {title}\n\n")
        report.append(f"- **ë‚ ì§œ**: {date_str}\n")
        report.append(f"- **ë§í¬**: [{url}]({url})\n")
        report.append(f"- **ìˆ˜ì§‘ ì‹œê°„**: {scraped_time}\n\n")
    
    # í‘¸í„°
    report.append("---\n\n")
    report.append("## ğŸ“Œ ì •ë³´\n\n")
    report.append(f"- **ì¹´í…Œê³ ë¦¬**: {category}\n")
    report.append(f"- **ì¶œì²˜**: {source}\n")
    report.append(f"- **ë°ì´í„° íŒŒì¼**: `data/{CATEGORY_EN_MAP.get(category, category.lower())}/{SOURCE_EN_MAP.get(source, source.lower())}/news_{date}.json`\n\n")
    
    # íŒŒì¼ ì €ì¥
    category_en = CATEGORY_EN_MAP.get(category, category.lower())
    source_en = SOURCE_EN_MAP.get(source, source.lower().replace(' ', '_'))
    output_file = REPORT_TEMPLATE.format(category=category_en, source=source_en, date=date)
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(report))
    
    return output_file


def generate_combined_report(date: str) -> str:
    """
    ëª¨ë“  ì¹´í…Œê³ ë¦¬/ì†ŒìŠ¤ì˜ ë‰´ìŠ¤ë¥¼ í†µí•©í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        date: ë‚ ì§œ (YYYY-MM-DD)
        
    Returns:
        ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
    """
    # ëª¨ë“  ë‰´ìŠ¤ ë¡œë“œ
    all_data = load_all_news_by_date(date)
    
    if not all_data:
        print("âš ï¸ ë¡œë“œí•  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë³´ê³ ì„œ ìƒì„±
    report = []
    report_date = datetime.strptime(date, '%Y-%m-%d').strftime('%Yë…„ %mì›” %dì¼')
    
    # ì´ ë‰´ìŠ¤ ê°œìˆ˜ ê³„ì‚°
    total_count = sum(len(news) for sources in all_data.values() for news in sources.values())
    
    report.append(f"# ğŸ“° ì¢…í•© ë‰´ìŠ¤ ë³´ê³ ì„œ - {report_date}\n\n")
    report.append(f"**ë³´ê³ ì„œ ìƒì„±ì¼**: {get_kst_now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')} (KST)\n")
    report.append(f"**ì´ ë‰´ìŠ¤ ê°œìˆ˜**: {total_count}ê°œ\n")
    report.append("---\n\n")
    
    # ëª©ì°¨
    report.append("## ğŸ“‘ ëª©ì°¨\n\n")
    for category in sorted(all_data.keys()):
        category_count = sum(len(news) for news in all_data[category].values())
        anchor = category.lower().replace(' ', '-')
        report.append(f"- [{category}](#{anchor}) ({category_count}ê°œ)\n")
    report.append("\n---\n\n")
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    report.append("## ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n\n")
    report.append("| ì¹´í…Œê³ ë¦¬ | ë‰´ìŠ¤ ê°œìˆ˜ | ì£¼ìš” ì†ŒìŠ¤ |\n")
    report.append("|---------|----------|----------|\n")
    for category in sorted(all_data.keys()):
        sources = list(all_data[category].keys())
        category_count = sum(len(news) for news in all_data[category].values())
        sources_str = ', '.join(sources)
        report.append(f"| {category} | {category_count}ê°œ | {sources_str} |\n")
    report.append("\n---\n\n")
    
    # ìµœì‹  ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ (ì „ì²´ì—ì„œ ìƒìœ„ 10ê°œ)
    all_news_flat = []
    for category, sources_dict in all_data.items():
        for source, news_list in sources_dict.items():
            all_news_flat.extend(news_list)
    
    sorted_news = sorted(all_news_flat, key=lambda x: x.get('date', ''), reverse=True)
    
    report.append("## ğŸ”¥ ìµœì‹  ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸ (ì „ì²´)\n\n")
    for i, item in enumerate(sorted_news[:10], 1):
        title = clean_title(item['title'])
        date_str = item.get('date', 'ë‚ ì§œ ë¯¸ìƒ')
        main_category = item.get('main_category', 'ê¸°íƒ€')
        source = item.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
        url = item['url']
        
        report.append(f"### {i}. [{main_category}] {title}\n\n")
        report.append(f"- **ì¶œì²˜**: {source}\n")
        report.append(f"- **ë‚ ì§œ**: {date_str}\n")
        report.append(f"- **ë§í¬**: [{url}]({url})\n\n")
    
    report.append("---\n\n")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë‰´ìŠ¤
    report.append("## ğŸ“° ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë‰´ìŠ¤\n\n")
    
    for category in sorted(all_data.keys()):
        sources_dict = all_data[category]
        category_total = sum(len(news) for news in sources_dict.values())
        
        report.append(f"### {category}\n\n")
        report.append(f"**ì´ {category_total}ê°œì˜ ë‰´ìŠ¤**\n\n")
        
        for source in sorted(sources_dict.keys()):
            news_list = sources_dict[source]
            report.append(f"#### {source} ({len(news_list)}ê°œ)\n\n")
            
            for idx, item in enumerate(news_list, 1):
                title = clean_title(item['title'])
                date_str = item.get('date', 'ë‚ ì§œ ë¯¸ìƒ')
                url = item['url']
                
                report.append(f"{idx}. **{title}**\n")
                report.append(f"   - ë‚ ì§œ: {date_str}\n")
                report.append(f"   - ë§í¬: [{url}]({url})\n\n")
            
            report.append("\n")
        
        report.append("---\n\n")
    
    # í‘¸í„°
    report.append("## ğŸ“Œ ë³´ê³ ì„œ ì •ë³´\n\n")
    report.append(f"- **í¬ë¡¤ë§ ì‹œìŠ¤í…œ**: Multi-Category News Crawler\n")
    report.append(f"- **ì§€ì› ì¹´í…Œê³ ë¦¬**: AI, ì •ì¹˜, ìŠ¤í¬ì¸ , ê²½ì œ\n")
    report.append(f"- **ë°ì´í„° ì €ì¥**: ì¹´í…Œê³ ë¦¬/ì†ŒìŠ¤ë³„ í´ë” êµ¬ì¡°\n")
    report.append(f"- **ìë™ ì—…ë°ì´íŠ¸**: ì„¤ì •ëœ ìŠ¤ì¼€ì¤„ì— ë”°ë¼\n")
    report.append(f"- **ë°ì´í„° í˜•ì‹**: JSON\n\n")
    
    # íŒŒì¼ ì €ì¥
    output_file = COMBINED_REPORT_TEMPLATE.format(date=date)
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(''.join(report))
    
    print(f"âœ… í†µí•© ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")
    
    # ê°œë³„ ì†ŒìŠ¤ë³„ ë³´ê³ ì„œë„ ìƒì„±
    print("\nğŸ“ ê°œë³„ ì†ŒìŠ¤ë³„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    source_reports = []
    for category, sources_dict in all_data.items():
        for source, news_list in sources_dict.items():
            source_report = generate_source_report(category, source, news_list, date)
            source_reports.append(source_report)
            print(f"  âœ“ [{category}/{source}] ë³´ê³ ì„œ ìƒì„±: {source_report}")
    
    return output_file


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    today = get_kst_now().strftime('%Y-%m-%d')
    
    print("=" * 60)
    print("ğŸ“° ì¢…í•© ë‰´ìŠ¤ ë³´ê³ ì„œ ìƒì„±ê¸°")
    print("=" * 60)
    print(f"\nğŸ“… ë‚ ì§œ: {today}")
    
    try:
        report_file = generate_combined_report(today)
        
        if report_file:
            print(f"âœ¨ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
            print("=" * 60)
        else:
            print("âš ï¸ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
