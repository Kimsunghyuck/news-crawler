name: Manual Crawl (ìˆ˜ë™ ì‹¤í–‰)

on:
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš©

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ ì½”ë“œ ì²´í¬ì•„ì›ƒ
      uses: actions/checkout@v4
      
    - name: ğŸ Python ì„¤ì •
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜
      run: |
        pip install -r requirements.txt
        
    - name: ğŸ•·ï¸ ë©€í‹° ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
      run: |
        python crawler.py
        
    - name: ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸
      run: |
        echo "ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:"
        echo "=== ì •ì¹˜ ì¹´í…Œê³ ë¦¬ ==="
        ls -la data/politics/*/
        echo "=== ìŠ¤í¬ì¸  ì¹´í…Œê³ ë¦¬ ==="
        ls -la data/sports/*/
        echo "=== ê²½ì œ ì¹´í…Œê³ ë¦¬ ==="
        ls -la data/economy/*/
        echo "=== ë³´ê³ ì„œ ==="
        ls -la reports/combined/
        echo ""
        echo "ğŸ“° ìµœì‹  ë‰´ìŠ¤ í†µê³„:"
        python -c "import json; import glob; pol=sum([len(json.load(open(f))) for f in glob.glob('data/politics/*/*.json')]); spo=sum([len(json.load(open(f))) for f in glob.glob('data/sports/*/*.json')]); eco=sum([len(json.load(open(f))) for f in glob.glob('data/economy/*/*.json')]); print(f'ì •ì¹˜: {pol}ê°œ, ìŠ¤í¬ì¸ : {spo}ê°œ, ê²½ì œ: {eco}ê°œ, ì´: {pol+spo+eco}ê°œ')"
        
    - name: ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì»¤ë°‹ ë° í‘¸ì‹œ
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "GitHub Actions Bot"
        git add data/ reports/ logs/
        
        if ! git diff --quiet --staged; then
          git commit -m "ğŸ¤– ìˆ˜ë™ í¬ë¡¤ë§ (ì •ì¹˜+ìŠ¤í¬ì¸ +ê²½ì œ 45ê°œ): $(TZ='Asia/Seoul' date +'%Y-%m-%d %H:%M:%S')"
          git push
          echo "âœ… ë³€ê²½ì‚¬í•­ì´ ì»¤ë°‹ë˜ê³  í‘¸ì‹œë˜ì—ˆìŠµë‹ˆë‹¤."
        else
          echo "â„¹ï¸ ìƒˆë¡œìš´ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."
        fi
