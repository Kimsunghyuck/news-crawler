name: Manual Crawl (ìˆ˜ë™ ì‹¤í–‰)

on:
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš©

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ ì½”ë“œ ì²´í¬ì•„ì›ƒ
      uses: actions/checkout@v4
      
    - name: ğŸ Python ì„¤ì •
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜
      run: |
        pip install -r requirements.txt
        
    - name: ğŸ•·ï¸ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
      run: |
        python crawler.py
        
    - name: ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸
      run: |
        echo "ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:"
        ls -la data/
        ls -la reports/
        echo ""
        echo "ğŸ“° ìµœì‹  ë‰´ìŠ¤ ê°œìˆ˜:"
        python -c "import json; import glob; files=glob.glob('data/news_*.json'); latest=sorted(files)[-1] if files else None; data=json.load(open(latest)) if latest else []; print(f'{len(data)}ê°œ')"
        
    - name: ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì»¤ë°‹ ë° í‘¸ì‹œ
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "GitHub Actions Bot"
        git add data/ reports/ logs/
        
        if ! git diff --quiet --staged; then
          git commit -m "ğŸ¤– ìˆ˜ë™ í¬ë¡¤ë§: $(date +'%Y-%m-%d %H:%M:%S')"
          git push
          echo "âœ… ë³€ê²½ì‚¬í•­ì´ ì»¤ë°‹ë˜ê³  í‘¸ì‹œë˜ì—ˆìŠµë‹ˆë‹¤."
        else
          echo "â„¹ï¸ ìƒˆë¡œìš´ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."
        fi
